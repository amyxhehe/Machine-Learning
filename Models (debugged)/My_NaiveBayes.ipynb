{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8xrt0InMf+mQPNK/M7qam"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import math"],"metadata":{"id":"yQScGzTl6nuw","executionInfo":{"status":"ok","timestamp":1746463268543,"user_tz":-300,"elapsed":123,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"id":"MDLEzsxIYuHT","executionInfo":{"status":"ok","timestamp":1746463268630,"user_tz":-300,"elapsed":12,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}}},"outputs":[],"source":["class NaiveBayesClassifier:\n","    def __init__(self):\n","        #probability variables\n","        self.class_p = {}\n","        self.feature_p = {}\n","\n","    def train(self, X, y):\n","        total_samples = len(y)\n","        self.class_p = {}\n","        self.feature_p = {}\n","\n","        #get unique classes i.e. yes & no\n","        classes = set(y)\n","\n","        #iterating on 'yes' and 'no' class\n","        for c in classes:\n","            c_count = y.count(c)  #no of samples in the current class\n","            self.class_p[c] = c_count / total_samples  #probability of getting a result from the current class out of the whole dataset\n","            #it looks like class_p = {'yes':...,'no':...}\n","\n","            #initialize feature probabilities for this class\n","            self.feature_p[c] = {}\n","\n","            #get all data samples of this class\n","            c_samples = [X[i] for i in range(total_samples) if y[i] == c]\n","            total_features = len(X[0])    #we have 2 features in our dataset i.e. weather & temperature\n","\n","            #iterating on each feature one by one\n","            for feature in range(total_features):\n","                values = [sample[feature] for sample in c_samples]\n","                value_counts = {}\n","                for val in values:  #iterating over each value i.e. overcast, rainy etc\n","                    #checking the dictionary for the current value\n","                    #if val exists as a key, it returns its current count i.e. increments\n","                    #if val doesn't exist, it returns the default value 0 i.e. creates a new key\n","                    value_counts[val] = value_counts.get(val, 0) + 1\n","\n","                #convert to probabilities\n","                total = len(values)\n","                for val, count in value_counts.items():\n","                    self.feature_p[c][(feature, val)] = count / total  #P(overcast∣yes), P(sunny∣yes), P(rainy∣yes)...\n","\n","    def predict(self, x):\n","        results = {}\n","        for c in self.class_p:\n","            log_prob = math.log(self.class_p[c])  #use log to avoid underflow, multiplying many small probabilities can cause numeric errors\n","            for i, val in enumerate(x):           #i is the feature index, val is the feature value\n","                #laplace smoothing\n","                #if the value is not in feature_p, it uses a small value 1e-6 as basic smoothing to avoid multiplying by 0.\n","                prob = self.feature_p[c].get((i, val), 1e-6)  #P(feature=val ∣ class=c)\n","                log_prob += math.log(prob)\n","            results[c] = log_prob  #looks like {'yes': ..., 'no': ...}\n","\n","        #return the key in results whose value is the largest.\n","        #compare based on the values, not the keys.\n","        return max(results, key=results.get)"]},{"cell_type":"code","source":["#sample dataset: [weather, temperature]\n","X = [['sunny', 'hot'],\n","     ['sunny', 'hot'],\n","     ['overcast', 'hot'],\n","     ['rainy', 'mild'],\n","     ['rainy', 'cool'],\n","     ['rainy', 'cool'],\n","     ['overcast', 'cool'],\n","     ['sunny', 'mild'],\n","     ['sunny', 'cool'],\n","     ['rainy', 'mild']]\n","\n","y = ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes']\n","\n","nb = NaiveBayesClassifier()\n","nb.train(X, y)\n","\n","test = ['sunny', 'cool']\n","print(\"Predicted class:\", nb.predict(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAvVf_YZ6jeT","executionInfo":{"status":"ok","timestamp":1746463268909,"user_tz":-300,"elapsed":256,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}},"outputId":"62dc152f-2a15-487e-f9e9-549bb733a37b"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: no\n"]}]}]}