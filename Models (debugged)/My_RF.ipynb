{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQS1/PY6id+Gx5ycC13PBu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"AleaPtg17P-m","executionInfo":{"status":"ok","timestamp":1716113323173,"user_tz":-300,"elapsed":1423,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QKJTKDse6TGM","executionInfo":{"status":"ok","timestamp":1716113325636,"user_tz":-300,"elapsed":11,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}}},"outputs":[],"source":["class DecisionTree:\n","    def __init__(self, d=None):\n","        self.max_depth = d\n","        self.tree = None\n","\n","\n","    def fit(self, X, y):\n","        self.tree = self._build_tree(X, y)\n","\n","\n","    def predict(self, X):\n","        return np.array([self.pred(inputs) for inputs in X])\n","\n","\n","    def _gini(self, y):\n","        #calculating the gini impurity\n","        m = len(y)\n","        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n","\n","\n","    def _split(self, X, y, index, value):\n","        #splitting the node\n","        left_mask = X[:, index] <= value\n","        right_mask = X[:, index] > value\n","        return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n","\n","\n","    def _best_split(self, X, y):\n","        #initializing the gini value to infinity (worst case)\n","        best_gini = float('inf')\n","        best_index, best_value = None, None\n","\n","        for index in range(X.shape[1]):\n","            #looping through all the unique values in the column\n","            for value in np.unique(X[:, index]):\n","                #splitting\n","                X_left, X_right, y_left, y_right = self._split(X, y, index, value)\n","                #checking if either splitted node is empty i.e. the splitting didn't occur\n","                if len(y_left) == 0 or len(y_right) == 0:\n","                    continue\n","                #calculating the gini impurity\n","                gini = (len(y_left) * self._gini(y_left) + len(y_right) * self._gini(y_right)) / len(y)\n","                #updating the best gini and the value that it belongs to\n","                if gini < best_gini:\n","                    best_gini, best_index, best_value = gini, index, value\n","        return best_index, best_value\n","\n","\n","    def _build_tree(self, X, y, depth=0):\n","        #condition that terminates the recursive building of the tree\n","        if len(np.unique(y)) == 1 or (self.max_depth and depth >= self.max_depth):\n","            return np.argmax(np.bincount(y))\n","\n","        #finding the best attribute to make the node that we would split\n","        index, value = self._best_split(X, y)\n","        if index is None:\n","            return np.argmax(np.bincount(y))\n","\n","        #splitting the node into left and right sub nodes\n","        X_left, X_right, y_left, y_right = self._split(X, y, index, value)\n","\n","        #recursively creating the left subtree\n","        left_subtree = self._build_tree(X_left, y_left, depth + 1)\n","        #recursively creating the right subtree\n","        right_subtree = self._build_tree(X_right, y_right, depth + 1)\n","\n","        return (index, value, left_subtree, right_subtree)\n","\n","\n","    def pred(self, inputs):\n","        node = self.tree\n","        while isinstance(node, tuple):\n","            if inputs[node[0]] <= node[1]:\n","                node = node[2]\n","            else:\n","                node = node[3]\n","        return node\n"]},{"cell_type":"code","source":["class RandomForest:\n","    def __init__(self, trees=100, d=None, bt=True, f='sqrt'):\n","        self.no_of_trees = trees\n","        self.max_depth = d\n","        self.bootstrap = bt\n","        self.max_features = f\n","        self.trees = []\n","\n","    def fit(self, X, y):\n","        self.trees = []\n","        no_of_samples, no_of_features = X.shape\n","\n","        for _ in range(self.no_of_trees):\n","            #creating different samples of data using bootstrap sampling technique\n","            #creating random samples of data to create different kinds of trees\n","            if self.bootstrap:\n","                indices = np.random.choice(no_of_samples, no_of_samples, replace=True)\n","            else:\n","                indices = np.arange(no_of_samples)\n","\n","            #selecting random features for each tree to be splitted upon\n","            #values close to the log and square root of the total no of features work the best\n","            if self.max_features == 'sqrt':\n","                max_features = int(np.sqrt(no_of_features))\n","            elif self.max_features == 'log2':\n","                max_features = int(np.log2(no_of_features))\n","            else:\n","                max_features = no_of_features\n","\n","            #dividng the sample into x and y subsets\n","            feature_indices = np.random.choice(no_of_features, max_features, replace=True)\n","            X_subset = X[indices][:, feature_indices]\n","            y_subset = y[indices]\n","\n","            #training the tree\n","            tree = DecisionTree(d=self.max_depth)\n","            tree.fit(X_subset, y_subset)\n","            self.trees.append((tree, feature_indices))\n","\n","    def predict(self, X):\n","        #collecting the predictions from each of the tree\n","        tree_preds = np.array([tree.predict(X[:, features]) for tree, features in self.trees])\n","        tree_preds = np.swapaxes(tree_preds, 0, 1)\n","        #finding the mode i.e. the most common prediction among all the predictions collected\n","        #in other words, finding the aggregate result\n","        y_pred = [Counter(tree_pred).most_common(1)[0][0] for tree_pred in tree_preds]\n","        #creating the result into an array\n","        return np.array(y_pred)"],"metadata":{"id":"SNZSPq467agD","executionInfo":{"status":"ok","timestamp":1716113341531,"user_tz":-300,"elapsed":23,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","if __name__ == \"__main__\":\n","    #loading the Iris dataset\n","    iris = load_iris()\n","    X, y = iris.data, iris.target\n","\n","    #splitting the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    #creating & training the Random Forest\n","    rf = RandomForest(trees=10, d=3)\n","    rf.fit(X_train, y_train)\n","\n","    predictions = rf.predict(X_test)\n","\n","    print(\"Predictions:  \", predictions)\n","    print(\"Actual labels:\", y_test)\n"],"metadata":{"id":"5p11HCtp7Kyj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716113470452,"user_tz":-300,"elapsed":29,"user":{"displayName":"Aeman Chaudhary","userId":"07954425247912789483"}},"outputId":"372a2609-3e26-4235-d1c9-34e84a4ff7fa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions:   [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n","Actual labels: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"]}]}]}